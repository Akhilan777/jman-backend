{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5525358a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd # data processing (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fade5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b248a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for input to tqdm\n",
    "def download_dataset(file_url, folder_path, name):\n",
    "    file_path = os.path.join(folder_path, name)\n",
    "    print(folder_path, file_path)\n",
    "    \n",
    "    r = requests.get(file_url, stream=True)\n",
    "    \n",
    "    with open(file_path, \"wb\") as file:\n",
    "        for chunk in tqdm(r.iter_content(chunk_size=1024)):\n",
    "             if chunk: file.write(chunk)\n",
    "\n",
    "    print(f'Download complete. File saved to: {file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc4a300",
   "metadata": {},
   "outputs": [],
   "source": [
    "backend_dir = os.path.dirname(os.getcwd())\n",
    "data_dir = os.path.join(backend_dir, 'data')\n",
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e5e01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_dataset(\"https://bitbucket.org/abdulwahed11314/accidents-data/raw/b7add9860d310171bca48bcaefeae37fe5157ac3/CasualtiesBig.csv\", data_dir, 'casualties.csv')\n",
    "download_dataset(\"https://bitbucket.org/abdulwahed11314/accidents-data/raw/b7add9860d310171bca48bcaefeae37fe5157ac3/AccidentsBig.csv\", data_dir, 'accidents.csv')\n",
    "download_dataset(\"https://bitbucket.org/abdulwahed11314/accidents-data/raw/b7add9860d310171bca48bcaefeae37fe5157ac3/VehiclesBig.csv\", data_dir, 'vehicles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cf6a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents_csv_file_path = os.path.join(data_dir, 'accidents.csv')\n",
    "vehicles_csv_file_path = os.path.join(data_dir, 'vehicles.csv')\n",
    "casualties_csv_file_path = os.path.join(data_dir, 'casualties.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff6ab40",
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents  = pd.read_csv(accidents_csv_file_path,  index_col='Accident_Index', on_bad_lines='skip')\n",
    "vehicles   = pd.read_csv(vehicles_csv_file_path,   index_col='Accident_Index', on_bad_lines='skip')\n",
    "casualties = pd.read_csv(casualties_csv_file_path, index_col='Accident_Index', on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19446e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_df = pd.merge(accidents, casualties, on='Accident_Index')\n",
    "df = pd.merge(first_df, vehicles, on='Accident_Index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a82442",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68a9fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of rows:\", df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038b2c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_df = df[df['Vehicle_Type'] == 11]\n",
    "# Assuming you have the filtered_df DataFrame with the 'Accident_Severity' column\n",
    "\n",
    "input_columns = ['Age_Band_of_Driver', 'Sex_of_Driver', 'Vehicle_Type',\n",
    "                 'Road_Type', 'Speed_limit', 'Junction_Control', 'Light_Conditions',\n",
    "                 'Weather_Conditions', 'Road_Surface_Conditions', 'Urban_or_Rural_Area','Accident_Severity']\n",
    "\n",
    "accident_ml = df[input_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f0a61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accident_ml.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7644b197",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = ['Age_Band_of_Driver', 'Sex_of_Driver', 'Vehicle_Type',\n",
    "                 'Road_Type', 'Speed_limit', 'Junction_Control', 'Light_Conditions',\n",
    "                 'Weather_Conditions', 'Road_Surface_Conditions', 'Urban_or_Rural_Area']\n",
    "target_column = 'Accident_Severity'\n",
    "\n",
    "\n",
    "\n",
    "mask = (accident_ml[input_columns] == -1).any(axis=1)\n",
    "\n",
    "# Use the mask to drop rows with -1 values\n",
    "cleaned_accident_ml = accident_ml[~mask]\n",
    "\n",
    "sev1=accident_ml[accident_ml['Accident_Severity'] == 1].head(100000)\n",
    "sev2=accident_ml[accident_ml['Accident_Severity'] == 2].head(40000)\n",
    "sev3=accident_ml[accident_ml['Accident_Severity'] == 3].head(40000)\n",
    "\n",
    "print(sev1.shape[0])\n",
    "print(sev2.shape[0])\n",
    "print(sev3.shape[0])\n",
    "\n",
    "combined_df = pd.concat([sev1, sev2, sev3], axis=0)\n",
    "\n",
    "# Reset the index if needed\n",
    "combined_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Prepare the data\n",
    "#X = cleaned_accident_ml[input_columns]\n",
    "#y = cleaned_accident_ml[target_column]\n",
    "\n",
    "X = combined_df[input_columns]\n",
    "y = combined_df[target_column]\n",
    "\n",
    "missing_values1 = X.isnull().sum()\n",
    "missing_values2 = y.isnull().sum()\n",
    "print(accident_ml.shape[0])\n",
    "print(X.shape[0])\n",
    "print(y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bf7b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape[0])\n",
    "print(y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be131026",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4140309b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20, shuffle=True, random_state=99)\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=200)\n",
    "\n",
    "random_forest.fit(X_train,y_train)\n",
    "Y_pred = random_forest.predict(X_test)\n",
    "random_forest.score(X_test, y_test)\n",
    "acc_random_forest1 = round(random_forest.score(X_test, y_test) * 100, 2)\n",
    "\n",
    "sk_report = classification_report(\n",
    "    digits=6,\n",
    "    y_true=y_test,\n",
    "    y_pred=Y_pred)\n",
    "print(\"Accuracy\" , acc_random_forest1)\n",
    "print(sk_report)\n",
    "pd.crosstab(y_test, Y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f71529",
   "metadata": {},
   "source": [
    "### this saves the model into a file 'accident_prediction_model.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a01c599",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "models_dir = os.path.join(backend_dir, 'models')\n",
    "file_name = 'accident_prediction_model.pkl'\n",
    "file_path = os.path.join(models_dir, file_name)\n",
    "joblib.dump(random_forest, file_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef57fdc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309d18ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d3c45ab",
   "metadata": {},
   "source": [
    "# testing the model with sample input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8562dc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample = [4,1,11,2,30,2,1,1,1,1]\n",
    "\n",
    "#sample = [8, 1, 11, 7, 30, 2, 5, 2, 5,1]\n",
    "\n",
    "sample = [7, 1, 11, \n",
    "          2 ,30, 4, 1, \n",
    "          1, 1,1]\n",
    "\n",
    "'''\n",
    "['Age_Band_of_Driver', 'Sex_of_Driver', 'Vehicle_Type',\n",
    "'Road_Type', 'Speed_limit', 'Junction_Control', 'Light_Conditions',\n",
    "'Weather_Conditions', 'Road_Surface_Conditions', 'Urban_or_Rural_Area']\n",
    "'''\n",
    "\n",
    "# Reshape the array\n",
    "sample = np.array(sample).reshape(1, -1)\n",
    "\n",
    "print(sample)\n",
    "\n",
    "result = random_forest.predict(sample)\n",
    "print(\"done\")\n",
    "\n",
    "predicted_class = result[0]\n",
    "\n",
    "print(\"Predicted Class:\", predicted_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff8c9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = [[7, 1, 11, 2, 30, 4, 1, 1, 1, 1]]  # Replace with your actual sample input\n",
    "\n",
    "# Calculate class probabilities for the sample input\n",
    "class_probabilities = random_forest.predict_proba(sample_input)\n",
    "\n",
    "# Print the probabilities for each class\n",
    "for class_label, probability in enumerate(class_probabilities[0]):\n",
    "    print(f\"Probability of being in Class {class_label + 1}: {probability:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47179e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample class probabilities (replace with actual class probabilities)\n",
    "probability_fatal = class_probabilities[0][0]  # Probability for fatal accident\n",
    "probability_serious = class_probabilities[0][1]  # Probability for serious accident\n",
    "probability_slight = class_probabilities[0][2]  # Probability for slight accident\n",
    "\n",
    "# Define weights for each severity class\n",
    "w_fatal = 0.5  # Weight for fatal accidents\n",
    "w_serious = 0.4  # Weight for serious accidents\n",
    "w_slight = 0.3  # Weight for slight accidents\n",
    "\n",
    "# Calculate the combined probability that an accident will happen\n",
    "combined_probability = (w_fatal * probability_fatal +\n",
    "                        w_serious * probability_serious +\n",
    "                        w_slight * probability_slight)\n",
    "print(f\"Combined Probability of an Accident: {combined_probability:.6f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
