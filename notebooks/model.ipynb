{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5525358a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd # data processing (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fade5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03b248a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for input to tqdm\n",
    "def download_dataset(file_url, folder_path, name):\n",
    "    file_path = os.path.join(folder_path, name)\n",
    "    print(folder_path, file_path)\n",
    "    \n",
    "    r = requests.get(file_url, stream=True)\n",
    "    \n",
    "    with open(file_path, \"wb\") as file:\n",
    "        for chunk in tqdm(r.iter_content(chunk_size=1024)):\n",
    "             if chunk: file.write(chunk)\n",
    "\n",
    "    print(f'Download complete. File saved to: {file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adc4a300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\jman\\jman-backend\\data\n"
     ]
    }
   ],
   "source": [
    "backend_dir = os.path.dirname(os.getcwd())\n",
    "data_dir = os.path.join(backend_dir, 'data')\n",
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15e5e01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\jman\\jman-backend\\data d:\\jman\\jman-backend\\data\\casualties.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103368it [00:23, 4353.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download complete. File saved to: d:\\jman\\jman-backend\\data\\casualties.csv\n",
      "d:\\jman\\jman-backend\\data d:\\jman\\jman-backend\\data\\accidents.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "237031it [00:48, 4911.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download complete. File saved to: d:\\jman\\jman-backend\\data\\accidents.csv\n",
      "d:\\jman\\jman-backend\\data d:\\jman\\jman-backend\\data\\vehicles.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "198729it [00:50, 3905.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download complete. File saved to: d:\\jman\\jman-backend\\data\\vehicles.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "download_dataset(\"https://bitbucket.org/abdulwahed11314/accidents-data/raw/b7add9860d310171bca48bcaefeae37fe5157ac3/CasualtiesBig.csv\", data_dir, 'casualties.csv')\n",
    "download_dataset(\"https://bitbucket.org/abdulwahed11314/accidents-data/raw/b7add9860d310171bca48bcaefeae37fe5157ac3/AccidentsBig.csv\", data_dir, 'accidents.csv')\n",
    "download_dataset(\"https://bitbucket.org/abdulwahed11314/accidents-data/raw/b7add9860d310171bca48bcaefeae37fe5157ac3/VehiclesBig.csv\", data_dir, 'vehicles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79cf6a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents_csv_file_path = os.path.join(data_dir, 'accidents.csv')\n",
    "vehicles_csv_file_path = os.path.join(data_dir, 'vehicles.csv')\n",
    "casualties_csv_file_path = os.path.join(data_dir, 'casualties.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dff6ab40",
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents  = pd.read_csv(accidents_csv_file_path,  index_col='Accident_Index', on_bad_lines='skip')\n",
    "vehicles   = pd.read_csv(vehicles_csv_file_path,   index_col='Accident_Index', on_bad_lines='skip')\n",
    "casualties = pd.read_csv(casualties_csv_file_path, index_col='Accident_Index', on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19446e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_df = pd.merge(accidents, casualties, on='Accident_Index')\n",
    "df = pd.merge(first_df, vehicles, on='Accident_Index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3a82442",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4287593 entries, 200501BS00001 to 2014984139614\n",
      "Data columns (total 66 columns):\n",
      " #   Column                                       Dtype  \n",
      "---  ------                                       -----  \n",
      " 0   Location_Easting_OSGR                        float64\n",
      " 1   Location_Northing_OSGR                       float64\n",
      " 2   Longitude                                    float64\n",
      " 3   Latitude                                     float64\n",
      " 4   Police_Force                                 int64  \n",
      " 5   Accident_Severity                            int64  \n",
      " 6   Number_of_Vehicles                           int64  \n",
      " 7   Number_of_Casualties                         int64  \n",
      " 8   Date                                         object \n",
      " 9   Day_of_Week                                  int64  \n",
      " 10  Time                                         object \n",
      " 11  Local_Authority_(District)                   int64  \n",
      " 12  Local_Authority_(Highway)                    object \n",
      " 13  1st_Road_Class                               int64  \n",
      " 14  1st_Road_Number                              int64  \n",
      " 15  Road_Type                                    int64  \n",
      " 16  Speed_limit                                  int64  \n",
      " 17  Junction_Detail                              int64  \n",
      " 18  Junction_Control                             int64  \n",
      " 19  2nd_Road_Class                               int64  \n",
      " 20  2nd_Road_Number                              int64  \n",
      " 21  Pedestrian_Crossing-Human_Control            int64  \n",
      " 22  Pedestrian_Crossing-Physical_Facilities      int64  \n",
      " 23  Light_Conditions                             int64  \n",
      " 24  Weather_Conditions                           int64  \n",
      " 25  Road_Surface_Conditions                      int64  \n",
      " 26  Special_Conditions_at_Site                   int64  \n",
      " 27  Carriageway_Hazards                          int64  \n",
      " 28  Urban_or_Rural_Area                          int64  \n",
      " 29  Did_Police_Officer_Attend_Scene_of_Accident  int64  \n",
      " 30  LSOA_of_Accident_Location                    object \n",
      " 31  Vehicle_Reference_x                          int64  \n",
      " 32  Casualty_Reference                           int64  \n",
      " 33  Casualty_Class                               int64  \n",
      " 34  Sex_of_Casualty                              int64  \n",
      " 35  Age_of_Casualty                              int64  \n",
      " 36  Age_Band_of_Casualty                         int64  \n",
      " 37  Casualty_Severity                            int64  \n",
      " 38  Pedestrian_Location                          int64  \n",
      " 39  Pedestrian_Movement                          int64  \n",
      " 40  Car_Passenger                                int64  \n",
      " 41  Bus_or_Coach_Passenger                       int64  \n",
      " 42  Pedestrian_Road_Maintenance_Worker           int64  \n",
      " 43  Casualty_Type                                int64  \n",
      " 44  Casualty_Home_Area_Type                      int64  \n",
      " 45  Vehicle_Reference_y                          int64  \n",
      " 46  Vehicle_Type                                 int64  \n",
      " 47  Towing_and_Articulation                      int64  \n",
      " 48  Vehicle_Manoeuvre                            int64  \n",
      " 49  Vehicle_Location-Restricted_Lane             int64  \n",
      " 50  Junction_Location                            int64  \n",
      " 51  Skidding_and_Overturning                     int64  \n",
      " 52  Hit_Object_in_Carriageway                    int64  \n",
      " 53  Vehicle_Leaving_Carriageway                  int64  \n",
      " 54  Hit_Object_off_Carriageway                   int64  \n",
      " 55  1st_Point_of_Impact                          int64  \n",
      " 56  Was_Vehicle_Left_Hand_Drive?                 int64  \n",
      " 57  Journey_Purpose_of_Driver                    int64  \n",
      " 58  Sex_of_Driver                                int64  \n",
      " 59  Age_of_Driver                                int64  \n",
      " 60  Age_Band_of_Driver                           int64  \n",
      " 61  Engine_Capacity_(CC)                         int64  \n",
      " 62  Propulsion_Code                              int64  \n",
      " 63  Age_of_Vehicle                               int64  \n",
      " 64  Driver_IMD_Decile                            int64  \n",
      " 65  Driver_Home_Area_Type                        int64  \n",
      "dtypes: float64(4), int64(58), object(4)\n",
      "memory usage: 2.1+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f68a9fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 4287593\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows:\", df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "038b2c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_df = df[df['Vehicle_Type'] == 11]\n",
    "# Assuming you have the filtered_df DataFrame with the 'Accident_Severity' column\n",
    "\n",
    "input_columns = ['Age_Band_of_Driver', 'Sex_of_Driver', 'Vehicle_Type',\n",
    "                 'Road_Type', 'Speed_limit', 'Junction_Control', 'Light_Conditions',\n",
    "                 'Weather_Conditions', 'Road_Surface_Conditions', 'Urban_or_Rural_Area','Accident_Severity']\n",
    "\n",
    "accident_ml = df[input_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7f0a61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4287593 entries, 200501BS00001 to 2014984139614\n",
      "Data columns (total 11 columns):\n",
      " #   Column                   Dtype\n",
      "---  ------                   -----\n",
      " 0   Age_Band_of_Driver       int64\n",
      " 1   Sex_of_Driver            int64\n",
      " 2   Vehicle_Type             int64\n",
      " 3   Road_Type                int64\n",
      " 4   Speed_limit              int64\n",
      " 5   Junction_Control         int64\n",
      " 6   Light_Conditions         int64\n",
      " 7   Weather_Conditions       int64\n",
      " 8   Road_Surface_Conditions  int64\n",
      " 9   Urban_or_Rural_Area      int64\n",
      " 10  Accident_Severity        int64\n",
      "dtypes: int64(11)\n",
      "memory usage: 392.5+ MB\n"
     ]
    }
   ],
   "source": [
    "accident_ml.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7644b197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83607\n",
      "40000\n",
      "40000\n",
      "4287593\n",
      "163607\n",
      "163607\n"
     ]
    }
   ],
   "source": [
    "input_columns = ['Age_Band_of_Driver', 'Sex_of_Driver', 'Vehicle_Type',\n",
    "                 'Road_Type', 'Speed_limit', 'Junction_Control', 'Light_Conditions',\n",
    "                 'Weather_Conditions', 'Road_Surface_Conditions', 'Urban_or_Rural_Area']\n",
    "target_column = 'Accident_Severity'\n",
    "\n",
    "\n",
    "\n",
    "mask = (accident_ml[input_columns] == -1).any(axis=1)\n",
    "\n",
    "# Use the mask to drop rows with -1 values\n",
    "cleaned_accident_ml = accident_ml[~mask]\n",
    "\n",
    "sev1=accident_ml[accident_ml['Accident_Severity'] == 1].head(100000)\n",
    "sev2=accident_ml[accident_ml['Accident_Severity'] == 2].head(40000)\n",
    "sev3=accident_ml[accident_ml['Accident_Severity'] == 3].head(40000)\n",
    "\n",
    "print(sev1.shape[0])\n",
    "print(sev2.shape[0])\n",
    "print(sev3.shape[0])\n",
    "\n",
    "combined_df = pd.concat([sev1, sev2, sev3], axis=0)\n",
    "\n",
    "# Reset the index if needed\n",
    "combined_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Prepare the data\n",
    "#X = cleaned_accident_ml[input_columns]\n",
    "#y = cleaned_accident_ml[target_column]\n",
    "\n",
    "X = combined_df[input_columns]\n",
    "y = combined_df[target_column]\n",
    "\n",
    "missing_values1 = X.isnull().sum()\n",
    "missing_values2 = y.isnull().sum()\n",
    "print(accident_ml.shape[0])\n",
    "print(X.shape[0])\n",
    "print(y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06bf7b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163607\n",
      "163607\n"
     ]
    }
   ],
   "source": [
    "print(X.shape[0])\n",
    "print(y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be131026",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4140309b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 69.42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1   0.781931  0.837864  0.808932     16776\n",
      "           2   0.549706  0.268841  0.361088      8001\n",
      "           3   0.600665  0.819006  0.693045      7945\n",
      "\n",
      "    accuracy                       0.694151     32722\n",
      "   macro avg   0.644101  0.641904  0.621022     32722\n",
      "weighted avg   0.681137  0.694151  0.671290     32722\n",
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20, shuffle=True, random_state=99)\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=200)\n",
    "\n",
    "random_forest.fit(X_train,y_train)\n",
    "Y_pred = random_forest.predict(X_test)\n",
    "random_forest.score(X_test, y_test)\n",
    "acc_random_forest1 = round(random_forest.score(X_test, y_test) * 100, 2)\n",
    "\n",
    "sk_report = classification_report(\n",
    "    digits=6,\n",
    "    y_true=y_test,\n",
    "    y_pred=Y_pred)\n",
    "print(\"Accuracy\" , acc_random_forest1)\n",
    "print(sk_report)\n",
    "pd.crosstab(y_test, Y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f71529",
   "metadata": {},
   "source": [
    "### this saves the model into a file 'accident_prediction_model.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a01c599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d:\\\\jman\\\\jman-backend\\\\models\\\\accident_prediction_model.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "models_dir = os.path.join(backend_dir, 'models')\n",
    "file_name = 'accident_prediction_model.pkl'\n",
    "file_path = os.path.join(models_dir, file_name)\n",
    "joblib.dump(random_forest, file_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef57fdc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309d18ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d3c45ab",
   "metadata": {},
   "source": [
    "# testing the model with sample input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8562dc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7  1 11  2 30  4  1  1  1  1]]\n",
      "done\n",
      "Predicted Class: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\jman\\jman-backend\\venv\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#sample = [4,1,11,2,30,2,1,1,1,1]\n",
    "\n",
    "#sample = [8, 1, 11, 7, 30, 2, 5, 2, 5,1]\n",
    "\n",
    "sample = [7, 1, 11, \n",
    "          2 ,30, 4, 1, \n",
    "          1, 1,1]\n",
    "\n",
    "'''\n",
    "['Age_Band_of_Driver', 'Sex_of_Driver', 'Vehicle_Type',\n",
    "'Road_Type', 'Speed_limit', 'Junction_Control', 'Light_Conditions',\n",
    "'Weather_Conditions', 'Road_Surface_Conditions', 'Urban_or_Rural_Area']\n",
    "'''\n",
    "\n",
    "# Reshape the array\n",
    "sample = np.array(sample).reshape(1, -1)\n",
    "\n",
    "print(sample)\n",
    "\n",
    "result = random_forest.predict(sample)\n",
    "print(\"done\")\n",
    "\n",
    "predicted_class = result[0]\n",
    "\n",
    "print(\"Predicted Class:\", predicted_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ff8c9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of being in Class 1: 0.294271\n",
      "Probability of being in Class 2: 0.298233\n",
      "Probability of being in Class 3: 0.407497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\jman\\jman-backend\\venv\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sample_input = [[7, 1, 11, 2, 30, 4, 1, 1, 1, 1]]  # Replace with your actual sample input\n",
    "\n",
    "# Calculate class probabilities for the sample input\n",
    "class_probabilities = random_forest.predict_proba(sample_input)\n",
    "\n",
    "# Print the probabilities for each class\n",
    "for class_label, probability in enumerate(class_probabilities[0]):\n",
    "    print(f\"Probability of being in Class {class_label + 1}: {probability:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47179e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Probability of an Accident: 0.388677\n"
     ]
    }
   ],
   "source": [
    "# Sample class probabilities (replace with actual class probabilities)\n",
    "probability_fatal = class_probabilities[0][0]  # Probability for fatal accident\n",
    "probability_serious = class_probabilities[0][1]  # Probability for serious accident\n",
    "probability_slight = class_probabilities[0][2]  # Probability for slight accident\n",
    "\n",
    "# Define weights for each severity class\n",
    "w_fatal = 0.5  # Weight for fatal accidents\n",
    "w_serious = 0.4  # Weight for serious accidents\n",
    "w_slight = 0.3  # Weight for slight accidents\n",
    "\n",
    "# Calculate the combined probability that an accident will happen\n",
    "combined_probability = (w_fatal * probability_fatal +\n",
    "                        w_serious * probability_serious +\n",
    "                        w_slight * probability_slight)\n",
    "print(f\"Combined Probability of an Accident: {combined_probability:.6f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
